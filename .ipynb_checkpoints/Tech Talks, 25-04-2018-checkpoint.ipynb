{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Criando um modelo no Keras e publicando através de uma API"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Este notebook define o modelo utilizado no treinamento da base do Titanic disponível no Kaggle. Esta base foi escolhida por ter fácil compreensão e por ter sido utilizada como introdução ao aprendizado de Machine Learning."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Na célula abaixo, nós importamos as bibliotecas que serão utilizadas ao longo do experimento. Observe que utilizamos o pandas, numpy, keras e sklearn. Procure concentrar suas importações no começo do seu notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importando as bibliotecas e carregando os arquivos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/daniel/myenv/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout\n",
    "from sklearn.model_selection import train_test_split\n",
    "from IPython.display import clear_output\n",
    "from keras.callbacks import Callback\n",
    "\n",
    "from keras.models import model_from_json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Após a inclusão de todas as bibliotecas necessárias para o experimento, armazenaremos o conteúdo dos arquivos em memória, através de DataFrames do Pandas. Já fiz uma introdução dos conceitos do Pandas [neste artigo](https://labs.bawi.io/introdu%C3%A7%C3%A3o-ao-pandas-ea6c532470d5). Se preferir, aproveite para completar os desafios que propus lá, antes de prosseguir com este nosso estudo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('train.csv')\n",
    "train, test = train_test_split(train, test_size=.2)\n",
    "toPredict  = pd.read_csv('toPredict.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aqui, a novidade é a função **train_test_split** que, como o próprio nome sugere, dividiu um DataFrame em duas partes, a de treino e a de teste, sendo que a de teste possui 20% do tamanho total da base de treino original. Os outros 80% foi definido como a nova base de treino. Veja só:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Treinamento: 0.7991021324354658\n",
      "Teste: 0.20089786756453423\n"
     ]
    }
   ],
   "source": [
    "tamanho_treinamento = len(train)\n",
    "tamanho_teste = len(test)\n",
    "tamanho_total = tamanho_treinamento + tamanho_teste\n",
    "\n",
    "print('Treinamento:', tamanho_treinamento / tamanho_total)\n",
    "print('Teste:', tamanho_teste / tamanho_total)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analisando e corrigindo os dados da base"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Uma fase importante do nosso experimento, e de outros que você possa realizar, será a limpeza e organização dos dados. Veja na base de treinamento que os campos **Age** e **Cabin** possuem valores não preenchidos. Outras colunas também não foram preenchidas nas outras bases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 712 entries, 844 to 669\n",
      "Data columns (total 12 columns):\n",
      "PassengerId    712 non-null int64\n",
      "Survived       712 non-null int64\n",
      "Pclass         712 non-null int64\n",
      "Name           712 non-null object\n",
      "Sex            712 non-null object\n",
      "Age            574 non-null float64\n",
      "SibSp          712 non-null int64\n",
      "Parch          712 non-null int64\n",
      "Ticket         712 non-null object\n",
      "Fare           712 non-null float64\n",
      "Cabin          165 non-null object\n",
      "Embarked       711 non-null object\n",
      "dtypes: float64(2), int64(5), object(5)\n",
      "memory usage: 72.3+ KB\n"
     ]
    }
   ],
   "source": [
    "train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 179 entries, 183 to 98\n",
      "Data columns (total 12 columns):\n",
      "PassengerId    179 non-null int64\n",
      "Survived       179 non-null int64\n",
      "Pclass         179 non-null int64\n",
      "Name           179 non-null object\n",
      "Sex            179 non-null object\n",
      "Age            140 non-null float64\n",
      "SibSp          179 non-null int64\n",
      "Parch          179 non-null int64\n",
      "Ticket         179 non-null object\n",
      "Fare           179 non-null float64\n",
      "Cabin          39 non-null object\n",
      "Embarked       178 non-null object\n",
      "dtypes: float64(2), int64(5), object(5)\n",
      "memory usage: 18.2+ KB\n"
     ]
    }
   ],
   "source": [
    "test.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 418 entries, 0 to 417\n",
      "Data columns (total 11 columns):\n",
      "PassengerId    418 non-null int64\n",
      "Pclass         418 non-null int64\n",
      "Name           418 non-null object\n",
      "Sex            418 non-null object\n",
      "Age            332 non-null float64\n",
      "SibSp          418 non-null int64\n",
      "Parch          418 non-null int64\n",
      "Ticket         418 non-null object\n",
      "Fare           417 non-null float64\n",
      "Cabin          91 non-null object\n",
      "Embarked       418 non-null object\n",
      "dtypes: float64(2), int64(4), object(5)\n",
      "memory usage: 36.0+ KB\n"
     ]
    }
   ],
   "source": [
    "toPredict.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "De maneira simples, apenas preencheremos com a média nos campos numéricos e criaremos uma categoria **'I'** para o campo **Embarked**. Estes ajustes podem ser realizados de forma mais precisa, talvez agregando os valores de grupos mais próximos ao invés de uma média geral."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.Age.fillna(train.Age.mean(), inplace=True)\n",
    "test.Age.fillna(test.Age.mean(), inplace=True)\n",
    "toPredict.Age.fillna(toPredict.Age.mean(), inplace=True)\n",
    "\n",
    "train.Embarked.fillna('I', inplace=True)\n",
    "test.Embarked.fillna('I', inplace=True)\n",
    "toPredict.Embarked.fillna('I', inplace=True)\n",
    "\n",
    "train.Fare.fillna(train.Fare.mean(), inplace=True)\n",
    "test.Fare.fillna(test.Fare.mean(), inplace=True)\n",
    "toPredict.Fare.fillna(toPredict.Fare.mean(), inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Seleção das características e preparação para o treinamento"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Agora, de fato, selecionaremos apenas as colunas que utilizaremos durante o treinamento. Nas colunas categóricas, aplicamos uma técnica conhecida como One-Hot Encoding, através da função **[pd.get_dummies()](http://pandas.pydata.org/pandas-docs/version/0.17.0/generated/pandas.get_dummies.html)**. Tem um conteúdo muito bom sobre este assunto [aqui](https://www.kaggle.com/dansbecker/using-categorical-data-with-one-hot-encoding)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_cols = ['Pclass', 'Sex', 'Age', 'SibSp',\n",
    "       'Parch', 'Fare', 'Embarked']\n",
    "y_cols = ['Survived']\n",
    "OneHot_cols = ['Pclass', 'Sex', 'Embarked']\n",
    "\n",
    "X_train, y_train = train[X_cols], train[y_cols]\n",
    "X_test, y_test = test[X_cols], test[y_cols]\n",
    "X_toPredict = toPredict[X_cols]\n",
    "\n",
    "X_train = pd.get_dummies(X_train, columns=OneHot_cols)\n",
    "X_test = pd.get_dummies(X_test, columns=OneHot_cols)\n",
    "X_toPredict = pd.get_dummies(X_toPredict, columns=OneHot_cols)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nas células abaixo, observe como as colunas ficaram. A coluna sexo, que antes apresentava valores **female** e **male** foi transformada em duas colunas **Sex_male** e **Sex_female**, com inteiros 0 e 1 indicando seus valores. Exemplo de One-Hot Encoding aplicada em uma base de dados:\n",
    "\n",
    "**Base original**\n",
    "\n",
    "| Fruta | Cor |\n",
    "| --- | --- |\n",
    "| Banana | Amarelo |\n",
    "| Limão | Verde |\n",
    "| Morango | Vermelho |\n",
    "\n",
    "**Base com a aplicação de One-Hot Encoding na coluna Cor**\n",
    "\n",
    "| Fruta | Cor_Amarelo | Cor_Verde | Cor_Vermelho |\n",
    "| --- | --- | --- | --- |\n",
    "| Banana | 1 | 0 | 0 |\n",
    "| Limão | 0 | 1 | 0 |\n",
    "| Morango | 0 | 0 | 1 |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 712 entries, 844 to 669\n",
      "Data columns (total 13 columns):\n",
      "Age           712 non-null float64\n",
      "SibSp         712 non-null int64\n",
      "Parch         712 non-null int64\n",
      "Fare          712 non-null float64\n",
      "Pclass_1      712 non-null uint8\n",
      "Pclass_2      712 non-null uint8\n",
      "Pclass_3      712 non-null uint8\n",
      "Sex_female    712 non-null uint8\n",
      "Sex_male      712 non-null uint8\n",
      "Embarked_C    712 non-null uint8\n",
      "Embarked_I    712 non-null uint8\n",
      "Embarked_Q    712 non-null uint8\n",
      "Embarked_S    712 non-null uint8\n",
      "dtypes: float64(2), int64(2), uint8(9)\n",
      "memory usage: 34.1 KB\n"
     ]
    }
   ],
   "source": [
    "X_train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 418 entries, 0 to 417\n",
      "Data columns (total 12 columns):\n",
      "Age           418 non-null float64\n",
      "SibSp         418 non-null int64\n",
      "Parch         418 non-null int64\n",
      "Fare          418 non-null float64\n",
      "Pclass_1      418 non-null uint8\n",
      "Pclass_2      418 non-null uint8\n",
      "Pclass_3      418 non-null uint8\n",
      "Sex_female    418 non-null uint8\n",
      "Sex_male      418 non-null uint8\n",
      "Embarked_C    418 non-null uint8\n",
      "Embarked_Q    418 non-null uint8\n",
      "Embarked_S    418 non-null uint8\n",
      "dtypes: float64(2), int64(2), uint8(8)\n",
      "memory usage: 16.4 KB\n"
     ]
    }
   ],
   "source": [
    "X_toPredict.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "É importante notar outra coisa: observe os campos **Embarked**, tanto da base de treinamento quando da base para predição. Veja que no treinamento temos **Embarked_I**, que está ausente na base para predição. Isto aconteceu porque não existia nenhum registro na base para predição cujo valor era **I**. Para que todas as bases tenham as mesmas colunas, faremos um alinhamento delas com a base de treinamento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test, _ = X_test.align(X_train, join='right', fill_value=0, axis=1)\n",
    "X_toPredict, _ = X_toPredict.align(X_train, join='right', fill_value=0, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O Pandas fornece a função **[df.align()](https://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.align.html)**. É bem simples de entender, vamos lá! Ela sempre retornará os dois dataframes, o que invocou a função e o que foi passado como argumento. Os dois, respectivamente, serão chamados de esquerda e direita. No nosso caso, queremos que o DataFrame da esquerda possua as mesmas colunas que o da direita. Então, a partir do DataFrame de teste (à esquerda) invocamos a função **align()** passando o DataFrame de treinamento (à direita) com o parâmetro **join='right'**, o que significa dizer que as colunas do DataFrame da direita serão utilizadas no alinhamento. O parâmetro possui outras variações, implicando na mudança da posição dos termos à direita e à esquerda."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train.shape (712, 13)\n",
      "y_train.shape (712, 1)\n",
      "X_test.shape (179, 13)\n",
      "y_test.shape (179, 1)\n",
      "X_toPredict.shape (418, 13)\n"
     ]
    }
   ],
   "source": [
    "print('X_train.shape', X_train.shape)\n",
    "print('y_train.shape', y_train.shape)\n",
    "print('X_test.shape', X_test.shape)\n",
    "print('y_test.shape', y_test.shape)\n",
    "print('X_toPredict.shape', X_toPredict.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Por fim, todas as bases possuem 13 colunas, sendo equivalentes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Treinamento"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O nosso modelo será construído no Keras, com algumas camadas. Também adicionaremos uma função de *callback* para que a saída seja limpa após o término de cada **epoch**, e evitar que apareça aquela barra de rolagem. Ainda vou pesquisar se tem um jeito mais simples de fazer isto, mas esta do *callback* foi a mais divertida ¯\\\\_(ツ)_/¯"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ClearOutputWhenEpochEnds(Callback):\n",
    "    def __init__(self):\n",
    "        self.epochs_history = []\n",
    "        \n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "        clear_output()\n",
    "        new_epoch = {\n",
    "            'number': epoch + 1,\n",
    "            'logs': logs,\n",
    "        }\n",
    "        self.epochs_history.append(new_epoch)\n",
    "        self.print_last_epochs(5)\n",
    "    \n",
    "    def print_last_epochs(self, quantity):\n",
    "        for epoch in self.epochs_history[-quantity:]:\n",
    "            number = epoch['number']\n",
    "            loss = epoch['logs']['loss']\n",
    "            accuracy = epoch['logs']['acc']\n",
    "            print('Epoch #%03d -> loss: %.4f, accuracy: %.4f' % (number, loss, accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #146 -> loss: 0.3314, accuracy: 0.8511\n",
      "Epoch #147 -> loss: 0.3715, accuracy: 0.8483\n",
      "Epoch #148 -> loss: 0.3296, accuracy: 0.8624\n",
      "Epoch #149 -> loss: 0.3309, accuracy: 0.8427\n",
      "Epoch #150 -> loss: 0.3442, accuracy: 0.8553\n",
      "179/179 [==============================] - 0s 546us/step\n"
     ]
    }
   ],
   "source": [
    "clearOutput = ClearOutputWhenEpochEnds()\n",
    "\n",
    "units = 256\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(units, input_dim=X_train.shape[1], activation='relu'))\n",
    "model.add(Dense(units, activation='relu'))\n",
    "model.add(Dense(units, activation='relu'))\n",
    "model.add(Dense(units, activation='relu'))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer='rmsprop',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.fit(X_train, y_train,\n",
    "          epochs=150,\n",
    "          batch_size=64,\n",
    "         callbacks=[clearOutput])\n",
    "score = model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('loss', 0.48109352455458826), ('acc', 0.8268156431240743)]\n"
     ]
    }
   ],
   "source": [
    "print(list(zip(model.metrics_names, score)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O treinamento acabou após 150 epochs (até que foi bem rápido). Alcançou uma precisão de cerca de 80% nos dados de teste."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A função [zip](https://docs.python.org/3.3/library/functions.html#zip) é vida ¯\\\\_(ツ)_/¯"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Agora que temos um modelo treinado, salvaremos ele em dois arquivos: no arquivo \\*.json ficará a arquitetura do nosso modelo, e no arquivo \\*.h5 serão armazenados os pesos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('model.json', 'w') as arquivo:\n",
    "    arquivo.write(model.to_json())\n",
    "\n",
    "model.save_weights(\"weights.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Agora que temos o modelo e os pesos salvos em dois arquivos, vamos voltar lá pro passo 3 no [artigo](https://www.google.com) pra dar sequência nos estudos. Até mais!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
